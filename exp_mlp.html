<!DOCTYPE html>
<html lang="en">
  <head>
    <link href='http://fonts.googleapis.com/css?family=Noticia+Text:400,700' rel='stylesheet' type='text/css' />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title> Experiments with a 2 layer MLP incorporating phone information | seaandsailor </title>

    <link rel="stylesheet" href="/theme/css/style.css" type="text/css" />
    <link rel="stylesheet" href="/theme/css/pygments.css" type="text/css" />
    <link rel="stylesheet" href="/theme/css/font-awesome.css" type="text/css"/>
        
    <script type= "text/javascript">
        var s = document.createElement('script');
        s.type = 'text/javascript';
        s.src = 'https:' == document.location.protocol ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js' : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; 
        s[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" + 
            "    config: ['MMLorHTML.js']," + 
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS','output/NativeMML']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," + 
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    tex2jax: { " +
            "        processEscapes: true }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax .mo, .MathJax .mi': {color: 'black ! important'}} " +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(s);
    </script>

  </head>
  <body>
    <div class=container>

      <div class=navigation>
        <ul>
            <li><a href="/index.html">Blog</a> </li>
            <li><a href="/tags.html">Tags</a> </li>
            <li><a href="/pages/resume.html">Resume</a> </li>
            <li><a href="/publications.html">Publications</a> </li>
            <li><a href="/pages/software.html">Software</a> </li>
            <li><a href="/pages/about.html">About</a> </li>
        </ul>
      </div>
      <div class=separator></div>        
        <div class=body>
    <h1 class="title"> Experiments with a 2 layer MLP incorporating phone information</h1>
    <p class=date> Mar 19, 2014 </p>
    <p>During the spring break I decided to run some experiments with MLPs as
generative models, using both acoustic samples and phone codes as input.
The experiment's objective is two-fold: I wanted to investigate if using
information from surrounding frames improves the models (when compared
to what our colleagues have found), and I also wanted to have a baseline
to compare to the models based on sparse coding that I have been working
on. In the experiments by
<a class="reference external" href="http://ift6266hjb.wordpress.com/2014/02/10/speech-synthesis-project-description-and-first-attempt-at-a-regression-mlp/">Hubert</a>,
<a class="reference external" href="http://jpraymond.wordpress.com/2014/02/27/results-with-a-one-hidden-layer-neural-net/">Jean-Phillipe</a>,
and <a class="reference external" href="http://twuilliam.wordpress.com/2014/02/27/quick-experiment-breaking-the-sin-in-one-line/">William</a>, only the acoustic samples information was used as
input.
<a class="reference external" href="http://amjadmahayri.wordpress.com/2014/02/27/frame-prediction-given-phoneme-window/">Amjad</a>
has already done some tests incorporating phone information, but it
seems he is using only the current phone.</p>
<p>In my experiments, I updated
<a class="reference external" href="http://vdumoulin.github.io/articles/timit-part-5">Vincent's</a> dataset
implementation in order to make it provide the phones corresponding to
the current, previous, and next frame. The code can be found in my
<a class="reference external" href="https://github.com/jfsantos/research">fork</a>. Previously I was using
Python code to setup pylearn2 experiments, but I decided to switch to
YAML for these experiments as I didn't need to do anything fancy. The
YAML for this experiment can be found
<a class="reference external" href="https://github.com/jfsantos/ift6266h14/blob/master/experiments/mlp_acoustic/ac160_ph3_rl2_malespkr.yaml">here</a> and the serialized model is <a class="reference external" href="https://github.com/jfsantos/ift6266h14/blob/master/experiments/mlp_acoustic/ac160_ph3_rl2_malespkr.pkl">here</a>.
The dataset was configured as follows:</p>
<ul class="simple">
<li>Frame length: 160 samples</li>
<li>Frame overlap: 0 (not ideal, but it can be seen as a subsampling of
the complete dataset)</li>
<li>Frames per example: 1</li>
<li>Number of predicted samples: 1</li>
<li>Phone information: one-hot encoded phone code for the previous,
current, and next frame</li>
</ul>
<p>With this configuration, each example is a vector with
<span class="math">\(160 + 3*62 = 346\)</span>
 values. The MLP was set-up and trained as
follows:</p>
<ul class="simple">
<li>Two rectified linear hidden layers (the first with 500 and the second
with 100 units)</li>
<li>Linear output layer with a single unit (a single sample is predicted
for each input)</li>
<li>Training algorithm: SGD with fixed learning rate of 0.01, running for
a maximum of 200 epochs (alternative convergence condition was set as
10 iterations with improvement lower than <span class="math">\(1^{-10}\)</span>
). The batch
size was of 512 examples.</li>
</ul>
<p>Total training time for this experiment was approximately 1.15 hours,
running on a CPU (Intel Core i7-2600, 8 GB RAM, with Theano running over
MKL and using 4 cores simultaneously). As mentioned before, I considered
10 iterations without improvement as the convergence condition, which
happened by the iteration 159. A plot for the training, testing, and
validation set errors can be seen below. The errors found after
convergence (for the normalized, i.e., centered and divided by the
standard deviation) were the following:</p>
<ul class="simple">
<li>Training error: 0.02284</li>
<li>Test error: 0.03309</li>
<li>Validation error: 0.05482</li>
</ul>
<p>A plot showing the evolution of the errors over epochs can be seen below.</p>
<img alt="" src="images/exp_mlp_1.png" />
<p>To evaluate the trained network as a synthesizer, I got a sequence of
phone codes straight out of a sentence in the validation set and used it
as input to the MLP. As I did not have a previous frame, the initial
input is a frame with only zeros on it. I played with a multiplicative
factor on the noise added to the Gaussian sampling as <a class="reference external" href="http://davidtob.wordpress.com/2014/03/14/generating-one-phone-from-one-timit-speaker/">David
did</a>,
as using directly the test error I ended up with bursts as can be seen
below. The following multiplicative factors were tested:
<tt class="docutils literal">[0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]</tt>. As using high noise levels ends
up corrupting too much the signal, I filtered them down to approximately
the telephone bandwidth (300-4000 Hz) with a <span class="math">\(4^{th}\)</span>
 order
Butterworth passband filter, just to reduce the overall effect of noisy
sampling. For low noise multipliers, all I got was a short burst and
then the output stays at zero. However, by increasing the noise level to
five times the mean square test error, apparently I got some more
structure: even though it has almost nothing to do with whatever should
have been synthesized, it does sound like multiple speakers babbling. The respective audio files and plots (acoustic waveform + spectrogram) can be seen below:</p>
<p> 0.01: <br>
<audio controls="controls" >
      <source src="files/y_noise_0.01.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 0.05: <br>
<audio controls="controls" >
      <source src="files/y_noise_0.05.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 0.1: <br>
<audio controls="controls" >
      <source src="files/y_noise_0.1.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 0.5: <br>
<audio controls="controls" >
      <source src="files/y_noise_0.5.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 1.0: <br>
<audio controls="controls" >
      <source src="files/y_noise_1.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 2.0: <br>
<audio controls="controls" >
      <source src="files/y_noise_2.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 5.0: <br>
<audio controls="controls" >
      <source src="files/y_noise_5.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p>
<p> 10.0: <br>
<audio controls="controls" >
      <source src="files/y_noise_10.ogg" type="audio/wav" />
      Your browser does not support the audio element.
</audio> </p><img alt="" src="images/exp_mlp_2.png" />
<p>One interesting thing: I did the same procedure to generate an output
during training, sometime around the <span class="math">\(130^{th}\)</span>
 iteration. The
output generated at that stage sounded much nicer than what I got
after the training finished, but unfortunately the pickled model was
overwritten because of the way I set up my YAML file, which overwrites
the old model every time an iteration improves the objective. The only
thing I kept was the output:</p>
<audio controls="controls" >
  <source controls src="files/malespkr_rl2_not_converged.ogg"> type="audio/ogg" />
  Your browser does not support the audio element.
</audio><div class="section" id="next-steps">
<h2>Next steps</h2>
<p>Moving forward, I will write in my next post about the (not so
successful) tests I did using sparse coding coefficients instead of
acoustic samples as inputs. I will also comment about some ideas to
incorporate more advanced models in my experiments.</p>
</div>

    
<div class=twitter>
<a href="https://twitter.com/share" class="twitter-share-button">Tweet</a>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="//platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</div>
    <p class=tags>This entry was tagged as
      <a href="/tag/ift6266.html">ift6266</a>
    </p>
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = ''; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>        </div>
        
<div class=footer>
  <p>&copy; Copyright <script language="JavaScript">var date = new Date(); document.write(date.getFullYear());</script> by jfsantos</p>
  <p> Powered by <a href="http://pypi.python.org/pypi/pelican/" target="_blank">Pelican</a>.  
    <a href="https://github.com/fjavieralba/flasky">Theme</a>  by <a href="http://fjavieralba.com">fjavieralba</a>
  </p> 
  <p>
    <div class=social style="font-size: 27px;">
      <ul>
        <script language="JavaScript">
          u = 'joao.eel';
          s = 'gmail.com';
          document.write('<a href=\"mailto:' + u + '@' + s + '\" target=\"_blank\">');
        </script>
            <li><i class="icon-envelope icon-large"></i> </li>
        </a>
        <a href="http://twitter.com/seaandsailor" target="_blank"> <li> <i class="icon-twitter-sign icon-large"> </li></i> </a>
        <a href="http://www.linkedin.com/pub/jo%C3%A3o-felipe-santos/9/3a/270"><li><i class="icon-linkedin-sign icon-large" ></i></li></a>
        <a href="http://github.com/jfsantos" target="_blank"> <li> <i class="icon-github-sign icon-large"></i> </li> </a>
        <a href="/feeds/all.rss.xml" rel="alternate" title="Recent Blog Posts"><li> <i class="icon-rss icon-large"></i> </li></a>
      </ul>
    </div>
  </p>
</div>    </div>
  </body>
</html>
